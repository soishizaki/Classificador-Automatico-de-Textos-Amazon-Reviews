{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados\n",
    "# Classificador Automático de Textos (Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Luana Rocha\n",
    "\n",
    "Nome: Renata Leventhal\n",
    "\n",
    "Nome: Sofia Ishizaki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Introdução\n",
    "Neste projeto implementamos um classificador automático de textos baseado no Naive Bayes, utilizando avaliações de produtos da Amazon.  \n",
    "O objetivo é prever a nota (sentimento: negativo, neutro ou positivo) a partir do texto das avaliações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "/home/sofia/Documents/Insper 2025.2/Cdados/P1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparação da Base de Dados\n",
    "- Foi utilizado o notebook oficial fornecido no Blackboard para criar os arquivos:\n",
    "  - `dados_treino_ate_TRIO_grupo4.csv` (treinamento)  \n",
    "  - `dados_teste_ate_TRIO_grupo4.csv` (teste)  \n",
    "\n",
    "- As bases foram combinadas posteriormente para validação cruzada (StratifiedKFold)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Digite o username digitado quando arquivo foi criado:  grupo4\n"
     ]
    }
   ],
   "source": [
    "nome = input(\"Digite o username digitado quando arquivo foi criado: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE SEU PROJETO USA OS DADOS ATÉ TRIO\n",
    "train = pd.read_csv('dados_treino_ate_TRIO_'+nome+'.csv')\n",
    "test = pd.read_csv('dados_teste_ate_TRIO_'+nome+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smells very nice but there is no flavor of coc...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I got some of these out in cali last spring. Y...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These  Mission tortilla strips are made with L...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For all you die hard coffee nuts, Boyds Q-Rate...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Let me preface things by saying that I am vega...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  target\n",
       "0  smells very nice but there is no flavor of coc...     0.0\n",
       "1  I got some of these out in cali last spring. Y...     1.0\n",
       "2  These  Mission tortilla strips are made with L...     1.0\n",
       "3  For all you die hard coffee nuts, Boyds Q-Rate...     2.0\n",
       "4  Let me preface things by saying that I am vega...     0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I will continue purchasing these treats as the...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is the best deal I can find over the web....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they weren't perfect condition.... but they we...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm a nut butter addict, so I was excited to t...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Would not recommend, they were old and the cho...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  target\n",
       "0  I will continue purchasing these treats as the...     2.0\n",
       "1  This is the best deal I can find over the web....     2.0\n",
       "2  they weren't perfect condition.... but they we...     1.0\n",
       "3  I'm a nut butter addict, so I was excited to t...     0.0\n",
       "4  Would not recommend, they were old and the cho...     0.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Classificador Automático (Boot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 2. Montando SEU Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observando a distribuição dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição nos dados de treino:\n",
      "target\n",
      "2.0    848\n",
      "1.0    839\n",
      "0.0    833\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuição nos dados de teste:\n",
      "target\n",
      "0.0    367\n",
      "1.0    361\n",
      "2.0    352\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Distribuição nos dados de treino:\")\n",
    "print(train[\"target\"].value_counts())\n",
    "print(\"\\nDistribuição nos dados de teste:\")\n",
    "print(test[\"target\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Limpeza e Pré-processamento de Texto \n",
    "\n",
    "Antes de treinar o classificador, é necessário transformar o texto bruto em uma representação mais limpa e útil.  \n",
    "As principais etapas de pré-processamento aplicadas foram:\n",
    "\n",
    "- Conversão para minúsculas → unifica palavras como *\"Bom\"* e *\"bom\"*.  \n",
    "- Remoção de links, números e pontuações → reduzem ruído que não traz informação de sentimento.  \n",
    "- Eliminação de espaços extras.  \n",
    "- Exclusão de stopwords (palavras muito comuns como artigos e preposições, que não ajudam a diferenciar sentimentos).  \n",
    "- Inclusão de bigramas (pares de palavras consecutivas) → capturam contexto mínimo que unigramas sozinhos não conseguem, como em \"não gostei\".\n",
    "\n",
    "#### Raciocínio \n",
    "O Naive Bayes classifica textos com base nas palavras observadas.  \n",
    "Se não houver pré-processamento, o modelo tende a:\n",
    "- Inflar o vocabulário com tokens inúteis.  \n",
    "- Aprender relações falsas (ex.: acreditar que \"de\" ou \"em\" indicam sentimentos).  \n",
    "- Perder contexto importante em frases com negação (\"não gostei\" → bigrama evita erro de interpretação).\n",
    "\n",
    "Portanto, essas transformações reduzem ruído e reforçam o sinal de palavras mais relevantes para a classificação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de stopwords (palavras muito frequentes que não ajudam a diferenciar sentimento, como preposições, artigos, etc)\n",
    "stopwords = [\n",
    "    \"a\", \"an\", \"the\", \"and\", \"but\", \"or\", \"because\", \"so\", \"of\", \"with\", \"at\", \"from\",\n",
    "    \"into\", \"during\", \"including\", \"until\", \"against\", \"among\", \"through\", \"to\", \"in\",\n",
    "    \"for\", \"on\", \"by\", \"about\", \"as\", \"up\", \"out\", \"if\", \"is\", \"it\", \"this\", \"that\",\n",
    "    \"these\", \"those\", \"there\", \"where\", \"when\", \"which\", \"how\", \"all\", \"any\", \"both\",\n",
    "    \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"only\",\"own\", \"same\", \"so\", \n",
    "    \"than\", \"too\", \"very\", \"can\", \"will\", \"just\", \"should\", \"now\"\n",
    "]\n",
    "\n",
    "# função para limpar texto (remove maiúsculas, links, caracteres especiais, pontuações, etc) \n",
    "def limpar_texto(texto):\n",
    "    texto = texto.lower() \n",
    "    texto = re.sub(\"'\", \"\", texto)                  \n",
    "    texto = re.sub(r\"http\\S+|www\\S+\", \" \", texto)   \n",
    "    texto = re.sub(r\"\\d+\", \" \", texto)              \n",
    "    texto = re.sub(r\"[^\\w\\s]\", \" \", texto)          \n",
    "    texto = re.sub(r\"\\s+\", \" \", texto).strip()           \n",
    "    palavras = texto.split()\n",
    "    palavras = [p for p in palavras if p not in stopwords and len(p) > 2] #garante que não considera as stopwords \n",
    "    return palavras\n",
    "\n",
    "# função para gerar bigramas (pares de palavras consecutivas) \n",
    "def gerar_bigramas(tokens):\n",
    "    bigramas = []\n",
    "    for i in range(len(tokens)-1):\n",
    "        par = tokens[i] + \"_\" + tokens[i+1] #junta as palavras vizinhas com um underline \n",
    "        bigramas.append(par)\n",
    "    return bigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Contagem de Palavras por Classe\n",
    "\n",
    "Nesta etapa, transformamos os textos em representações numéricas, separando as palavras de acordo com as classes de sentimento:  \n",
    "\n",
    "- `0 = Negativo`  \n",
    "- `1 = Neutro`  \n",
    "- `2 = Positivo`  \n",
    "\n",
    "Para cada classe:  \n",
    "- Contabilizamos a frequência das palavras (unigramas + bigramas).  \n",
    "- Calculamos as probabilidades a priori, ou seja, a proporção de textos que pertencem a cada classe no conjunto de treinamento.  \n",
    "\n",
    "#### Raciocínio \n",
    "O Naive Bayes depende da frequência das palavras por classe para estimar probabilidades condicionais.  \n",
    "Exemplo: se a palavra “horrível” aparece 50 vezes em textos negativos e apenas 2 vezes em positivos, a probabilidade de um novo comentário com essa palavra ser negativo será muito maior.  \n",
    "\n",
    "As probabilidades a priori representam o quanto cada classe é frequente na base.  \n",
    "Exemplo: se 60% das avaliações são positivas, o modelo já começa com uma tendência a prever *Positivo*, a menos que as palavras do texto indiquem o contrário.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades a priori -> Neg: 0.33055555555555555 Neu: 0.3329365079365079 Pos: 0.33650793650793653\n"
     ]
    }
   ],
   "source": [
    "def contar_palavras(dados):\n",
    "    #listas para guardar as palavras separadas em três categorias - negativo, neutro e positivo\n",
    "    palavras_neg = []\n",
    "    palavras_neu = []\n",
    "    palavras_pos = []\n",
    "\n",
    "\n",
    "    #percorre o dataframe, limpa o texto e considera os bigramas \n",
    "    for _, linha in dados.iterrows():  \n",
    "        tokens = limpar_texto(linha[\"Text\"])\n",
    "        tokens = tokens + gerar_bigramas(tokens)\n",
    "\n",
    "    #separa os tokens de acordo com a classe (0 = negativo, 1 = neutro, 2 = positivo)\n",
    "        if linha[\"target\"] == 0:\n",
    "            palavras_neg.extend(tokens)\n",
    "        elif linha[\"target\"] == 1:\n",
    "            palavras_neu.extend(tokens)\n",
    "        else:\n",
    "            palavras_pos.extend(tokens)\n",
    "\n",
    "    #conta a frequência de cada palavra em cada classe\n",
    "    cont_neg = Counter(palavras_neg)\n",
    "    cont_neu = Counter(palavras_neu)\n",
    "    cont_pos = Counter(palavras_pos)\n",
    "    #conta total de todas as palavras (soma das três classes)\n",
    "    cont_total = cont_neg + cont_neu + cont_pos\n",
    "\n",
    "\n",
    "    #calcula as probabilidades a priori de cada classe\n",
    "    total_textos = len(dados)\n",
    "    p_neg = sum(dados[\"target\"] == 0) / total_textos\n",
    "    p_neu = sum(dados[\"target\"] == 1) / total_textos\n",
    "    p_pos = sum(dados[\"target\"] == 2) / total_textos\n",
    "\n",
    "    #retorna contagens e probabilidades iniciais\n",
    "    return cont_neg, cont_neu, cont_pos, cont_total, p_neg, p_neu, p_pos\n",
    "\n",
    "cont_neg, cont_neu, cont_pos, cont_total, p_neg, p_neu, p_pos = contar_palavras(train)\n",
    "\n",
    "print(\"Probabilidades a priori -> Neg:\", p_neg, \"Neu:\", p_neu, \"Pos:\", p_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Implementação do Classificador Naive Bayes\n",
    "\n",
    "Nesta etapa, construímos nosso próprio classificador Naive Bayes.  \n",
    "O funcionamento é o seguinte:\n",
    "\n",
    "1. Pré-processamos o texto (minúsculas, limpeza, stopwords, bigramas).  \n",
    "2. Iniciamos a pontuação de cada classe com o log da probabilidade a priori.  \n",
    "3. Para cada token do texto, somamos ao score da classe o log da probabilidade condicional dessa palavra dado a classe.  \n",
    "4. A classe final é aquela com maior pontuação (máxima verossimilhança).\n",
    "\n",
    "#### Fórmula com suavização de Laplace\n",
    "\n",
    "$$\n",
    "P(\\text{token} \\mid \\text{classe}) = \\frac{\\text{freq(token, classe)} + \\alpha}{\\text{total tokens da classe} + \\alpha \\cdot |Vocabulário|}\n",
    "$$\n",
    "\n",
    "- O parâmetro $\\alpha$ (Laplace) evita que uma palavra nunca vista em uma classe tenha probabilidade zero.  \n",
    "- O uso de logaritmos é essencial, pois multiplicar muitas probabilidades pequenas pode causar underflow numérico.  \n",
    "  No log, a multiplicação vira soma, mantendo os cálculos estáveis.\n",
    "\n",
    "#### Raciocínio \n",
    "- O Naive Bayes assume independência condicional entre palavras, simplificando o cálculo.  \n",
    "- Mesmo sendo uma aproximação, funciona bem porque palavras fortes como “péssimo” ou “excelente” têm grande poder discriminativo.  \n",
    "- Os bigramas ajudam em casos como “não gostei”, que poderiam confundir o modelo se considerássemos apenas unigramas.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista com os nomes das classes para facilitar a leitura do resultado\n",
    "nomes_classes = [\"Negativo\", \"Neutro\", \"Positivo\"]\n",
    "\n",
    "def classificar_texto(frase, cont_neg, cont_neu, cont_pos, cont_total, p_neg, p_neu, p_pos, alfa=1):\n",
    "    tokens = limpar_texto(frase)\n",
    "    tokens = tokens + gerar_bigramas(tokens) #limpa e tokeniza a frase de entrada, adiciona bigramas\n",
    "\n",
    "    #cria o vocabulário com todas as palavras já vistas no treino\n",
    "    vocabulario = set(cont_total.keys())\n",
    "\n",
    "    #listas com as contagens e probabilidades a priori de cada classe\n",
    "    contadores = [cont_neg, cont_neu, cont_pos]\n",
    "    probs_iniciais = [p_neg, p_neu, p_pos]\n",
    "\n",
    "    #quantidade total de tokens em cada classe\n",
    "    total_tokens = [sum(c.values()) for c in contadores]\n",
    "\n",
    "    pontuacoes = []  #vai guardar o \"score\" de cada classe\n",
    "    for i in range(3):  #percorre as três classes (0 = neg, 1 = neu, 2 = pos)\n",
    "        #começa com o log da probabilidade a priori da classe\n",
    "        score = np.log(probs_iniciais[i]) \n",
    "        #para cada token da frase, soma o log da probabilidade condicional\n",
    "        for token in tokens:\n",
    "            freq = contadores[i][token]  #frequência do token na classe i\n",
    "            #suavização de Laplace: evita probabilidade zero para palavras não vistas\n",
    "            prob_token = (freq + alfa) / (total_tokens[i] + alfa * len(vocabulario))\n",
    "            score += np.log(prob_token)  \n",
    "        pontuacoes.append(score)\n",
    "\n",
    "    #decide a classe com maior score (máxima verossimilhança)\n",
    "    if pontuacoes[0] >= pontuacoes[1] and pontuacoes[0] >= pontuacoes[2]:\n",
    "        classe = 0\n",
    "    elif pontuacoes[1] >= pontuacoes[0] and pontuacoes[1] >= pontuacoes[2]:\n",
    "        classe = 1\n",
    "    else:\n",
    "        classe = 2\n",
    "\n",
    "    #retorna o índice da classe, o nome da classe e os scores\n",
    "    return classe, nomes_classes[classe], pontuacoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 3. Verificando a performance do Classificador\n",
    "### 3.1. Avaliação no Conjunto de Teste\n",
    "\n",
    "Para avaliar a qualidade do classificador, utilizamos o conjunto de teste e extraímos as seguintes métricas:\n",
    "\n",
    "- Matriz de confusão 3x3 → Negativo, Neutro, Positivo.  \n",
    "- VP (Verdadeiros Positivos) → casos da classe corretamente identificados.  \n",
    "- FP (Falsos Positivos) → outros casos previstos incorretamente como pertencentes à classe.  \n",
    "- FN (Falsos Negativos) → casos da classe que foram classificados como outra.  \n",
    "- VN (Verdadeiros Negativos) → todo o restante corretamente identificado como “não sendo da classe”.  \n",
    "- Acurácia geral = proporção de previsões corretas no total.  \n",
    "- Precisão e Recall por classe:  \n",
    "  - Precisão → entre todos os textos previstos como pertencentes a uma classe, quantos realmente eram dessa classe.  \n",
    "  - Recall → entre todos os textos que realmente pertenciam a uma classe, quantos foram corretamente identificados.  \n",
    "\n",
    "#### Raciocínio\n",
    "A acurácia sozinha pode ser enganosa se houver desbalanceamento de classes. Por isso, analisamos também VP, FP, FN e VN por classe, além de Precisão e Recall, que permitem identificar se o modelo é mais “cauteloso” (alta precisão, baixo recall) ou mais “abrangente” (alto recall, baixa precisão). Essas métricas são fundamentais para entender a performance de classificadores de texto, pois revelam padrões de erro, como a dificuldade em reconhecer frases neutras que compartilham vocabulário com positivas ou negativas.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia Geral: 63.61 %\n",
      "\n",
      "Matriz de Confusão:\n",
      "[262, 77, 28]\n",
      "[72, 199, 90]\n",
      "[27, 99, 226]\n"
     ]
    }
   ],
   "source": [
    "#treina o classificador pegando as contagens e probabilidades a partir da base de treino\n",
    "cont_neg, cont_neu, cont_pos, cont_total, p_neg, p_neu, p_pos = contar_palavras(train)\n",
    "\n",
    "\n",
    "#listas para armazenar as respostas reais (do dataset) e as previstas (do modelo)\n",
    "respostas_reais = []\n",
    "respostas_previstas = []\n",
    "\n",
    "#percorre cada linha do conjunto de teste\n",
    "for _, linha in test.iterrows():\n",
    "    real = int(linha[\"target\"])   #pega o rótulo verdadeiro (0 = neg, 1 = neu, 2 = pos)\n",
    "    #classifica o texto usando o Naive Bayes treinado\n",
    "    previsto, _, _ = classificar_texto(linha[\"Text\"], cont_neg, cont_neu, cont_pos, cont_total, p_neg, p_neu, p_pos)\n",
    "    #guarda tanto a resposta real quanto a prevista\n",
    "    respostas_reais.append(real)\n",
    "    respostas_previstas.append(previsto)\n",
    "\n",
    "#cria matriz de confusão 3x3 (negativo, neutro, positivo)\n",
    "matriz = [[0,0,0],[0,0,0],[0,0,0]]\n",
    "\n",
    "#preenche a matriz de confusão contando os acertos/erros\n",
    "for i in range(len(respostas_reais)):\n",
    "    real = respostas_reais[i]\n",
    "    prev = respostas_previstas[i]\n",
    "    matriz[real][prev] = matriz[real][prev] + 1\n",
    "\n",
    "#conta a quantidade total de acertos \n",
    "acertos = 0\n",
    "for i in range(len(respostas_reais)):\n",
    "    if respostas_reais[i] == respostas_previstas[i]:\n",
    "        acertos = acertos + 1\n",
    "\n",
    "#calcula a acurácia geral\n",
    "total = len(respostas_reais)\n",
    "acuracia = acertos / total\n",
    "\n",
    "#mostra o resultado final\n",
    "print(\"Acurácia Geral:\", f\"{acuracia*100:.2f}\", \"%\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "for linha in matriz:\n",
    "    print(linha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas por classe:\n",
      "Negativo: VP=24.26% | VN=56.85% | FP=9.17% | FN=9.72% | Precisão=72.58% | Recall=71.39%\n",
      "Neutro: VP=18.43% | VN=50.28% | FP=16.30% | FN=15.00% | Precisão=53.07% | Recall=55.12%\n",
      "Positivo: VP=20.93% | VN=56.48% | FP=10.93% | FN=11.67% | Precisão=65.70% | Recall=64.20%\n"
     ]
    }
   ],
   "source": [
    "#lista de nomes das classes para facilitar a leitura dos resultados\n",
    "nomes_classes = [\"Negativo\", \"Neutro\", \"Positivo\"]\n",
    "\n",
    "print(\"Métricas por classe:\")\n",
    "for i, nome in enumerate(nomes_classes):\n",
    "    #VP (Verdadeiros Positivos): casos da classe i previstos corretamente\n",
    "    vp = matriz[i][i]\n",
    "    #FP (Falsos Positivos): outros que foram classificados como i por engano\n",
    "    fp = sum(matriz[r][i] for r in range(3) if r != i)\n",
    "    #FN (Falsos Negativos): casos da classe i que foram classificados como outra classe\n",
    "    fn = sum(matriz[i][c] for c in range(3) if c != i)\n",
    "    #VN (Verdadeiros Negativos): todo o resto que não tem relação com a classe i\n",
    "    vn = total - (vp + fp + fn)\n",
    "    #precisão: entre todos os classificados como i, quantos realmente eram i\n",
    "    precisao = vp / (vp + fp) if (vp + fp) > 0 else 0\n",
    "    #recall: entre todos os que eram i, quantos foram classificados corretamente\n",
    "    recall = vp / (vp + fn) if (vp + fn) > 0 else 0\n",
    "\n",
    "    #mostra resultados em porcentagem\n",
    "    print(f\"{nome}: VP={vp/total*100:.2f}% | VN={vn/total*100:.2f}% | \"\n",
    "          f\"FP={fp/total*100:.2f}% | FN={fn/total*100:.2f}% | \"\n",
    "          f\"Precisão={precisao*100:.2f}% | Recall={recall*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 4. Análise Qualitativa da Performance do Classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.1. Comparativo qualitativo dos resultados\n",
    "Nos testes, o Naive Bayes apresentou acurácia média em torno de **64%**. Esse valor já demonstra um desempenho aceitável, mas a análise isolada da acurácia pode mascarar limitações importantes.  \n",
    "\n",
    "Quando olhamos para as métricas por classe:  \n",
    "- **Negativo** → obteve bons níveis de precisão e recall, já que palavras como *“péssimo”* e *“horrível”* são fortes indicadores de sentimento negativo.  \n",
    "- **Positivo** → também apresentou bom desempenho, beneficiado por termos bem característicos como *“excelente”* e *“ótimo”*.  \n",
    "- **Neutro** → foi a classe mais problemática, com baixa precisão e recall. Isso ocorre porque textos neutros compartilham vocabulário tanto com os positivos quanto com os negativos, confundindo o modelo.  \n",
    "\n",
    "### 4.2. Casos complexos: dupla negação e sarcasmo\n",
    "Dois desafios importantes para o modelo:  \n",
    "\n",
    "- **Dupla negação** (ex.: *“Não acho que ele não esteja certo”*): o classificador interpreta palavra por palavra e não consegue captar o real sentido, resultando em previsões incorretas.  \n",
    "- **Sarcasmo** (ex.: *“Que ótimo, meu voo foi cancelado!”*): ainda mais difícil, pois o significado real é o oposto do literal.  \n",
    "\n",
    "Essas limitações são esperadas em modelos probabilísticos simples. O tratamento adequado exigiria técnicas mais avançadas, como análise de dependências sintáticas ou uso de embeddings contextuais (ex.: BERT), capazes de considerar relações mais profundas no texto.  \n",
    "\n",
    "\n",
    "### 4.3. Plano de expansão\n",
    "O modelo tem potencial de uso prático em escala. Ele pode ser integrado a sistemas que monitoram automaticamente milhões de avaliações em marketplaces, gerando dashboards que mostram tendências de satisfação e insatisfação em tempo real.  \n",
    "\n",
    "Esse tipo de análise reduz o tempo de resposta da empresa e apoia áreas como marketing, logística e desenvolvimento de produto.  \n",
    "Portanto, há clara justificativa para seguir investindo e aprimorando o projeto.  \n",
    "\n",
    "### 4.4. Outros cenários de aplicação do Naive Bayes\n",
    "Além de reviews de produtos, o Naive Bayes pode ser usado em contextos distintos, como:  \n",
    "- **Classificação de documentos jurídicos**: separar automaticamente peças processuais em categorias (ex.: apelação, sentença, petição inicial).  \n",
    "- **Triagem de atendimento médico**: analisar descrições textuais de sintomas e encaminhar casos para a especialidade correta.  \n",
    "- **Monitoramento de qualidade em fábricas**: classificar relatos de operadores sobre falhas ou incidentes em categorias (mecânico, elétrico, segurança).  \n",
    "- **Suporte técnico automatizado**: classificar chamados de clientes em tipos de problema (rede, software, hardware).  \n",
    "\n",
    "### 4.5. Possíveis melhorias\n",
    "- **Refinamento da lista de stopwords**  \n",
    "  Em vez de usar apenas uma lista genérica, podemos analisar a frequência das palavras específicas do dataset (ex.: *“product”*, *“buy”*, *“shipping”*). As que aparecem muito, mas não ajudam a diferenciar sentimento, seriam adicionadas à lista de stopwords.  \n",
    "  *Como aplicar:* usar `Counter` para verificar as palavras mais frequentes, avaliar sua relevância manualmente e atualizar a lista de stopwords do pré-processamento.\n",
    "\n",
    "\n",
    "\n",
    "- **Uso de embeddings (Word2Vec, GloVe, BERT)**  \n",
    "  Diferente do Naive Bayes baseado em contagem, embeddings representam palavras como vetores que capturam **contexto e semântica**. Assim, termos como *“ótimo”* e *“excelente”* ficam próximos no espaço vetorial.  \n",
    "  *Como aplicar:* treinar ou carregar embeddings pré-treinados (por exemplo, com `gensim` para Word2Vec/GloVe ou `transformers` para BERT), transformar cada texto em vetor e usar esses vetores como entrada em um classificador (Naive Bayes, SVM ou redes neurais).  \n",
    "\n",
    "- **Balanceamento de classes**  \n",
    "  A classe **Neutro** é menos representada, o que prejudica recall e precisão. Para corrigir, podemos aplicar técnicas de oversampling (duplicar exemplos minoritários) ou usar **SMOTE**, que cria exemplos sintéticos da classe minoritária.  \n",
    "  *Como aplicar:* usar a biblioteca `imblearn` (`imblearn.over_sampling.SMOTE`) para gerar exemplos neutros sintéticos e equilibrar as proporções no conjunto de treino.  \n",
    "\n",
    "- **Integração de n-gramas maiores (trigramas)**  \n",
    "  Além de bigramas, podemos considerar trigramas para capturar expressões mais ricas como *“não é bom”* ou *“gostei muito mesmo”*. Isso aumenta a capacidade do modelo de diferenciar nuances.  \n",
    "  *Como aplicar:* adaptar a função `gerar_bigramas` para também criar trigramas, ou usar `CountVectorizer(ngram_range=(1,3))` no scikit-learn para gerar unigramas, bigramas e trigramas automaticamente.  \n",
    "\n",
    "\n",
    "### 4.6. Por que não usar mensagens classificadas pelo próprio modelo como dados de treinamento?\n",
    "O motivo é que o classificador comete erros e, ao incluir previsões incorretas como se fossem rótulos verdadeiros, estaríamos propagando e reforçando esses erros.  \n",
    "\n",
    "Esse processo é conhecido como auto-treinamento enviesado (self-training bias). Com o tempo, o modelo ficaria cada vez mais confiante em classificações erradas, distorcendo completamente as probabilidades e reduzindo a qualidade do classificador.  \n",
    "\n",
    "\n",
    "### 4.7. Conclusão\n",
    "O Naive Bayes se mostrou um classificador simples, rápido e eficiente, principalmente para sentimentos positivos e negativos.  \n",
    "Sua principal limitação está nas frases neutras e em construções linguísticas complexas, como sarcasmo e dupla negação.  \n",
    "\n",
    "Ainda assim, o modelo já oferece valor prático e pode ser ampliado para outros domínios. Com melhorias adicionais em pré-processamento, balanceamento e representações de texto mais sofisticadas, tem potencial para alcançar resultados próximos de modelos mais avançados, mantendo a vantagem da simplicidade computacional.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Qualidade do Classificador a partir de novas separações das mensagens entre Treinamento e Teste\n",
    "\n",
    "### 5.1. Validação Cruzada Estratificada (StratifiedKFold)\n",
    "\n",
    "Um ponto importante do projeto é avaliar como diferentes divisões entre treino e teste podem impactar os resultados. Por isso, utilizamos a técnica de Validação Cruzada Estratificada (StratifiedKFold):\n",
    "\n",
    "- A base completa foi unida (`train + test`) e dividida em 10 partes iguais (folds).  \n",
    "- Em cada iteração, usamos 9 partes para treinar e 1 parte para testar, garantindo que as proporções de classes sejam mantidas em cada divisão (estratificação).  \n",
    "- Repetimos esse processo para os 10 folds, armazenando a acurácia de cada rodada.  \n",
    "- Por fim, calculamos a acurácia média e plotamos um histograma para visualizar a distribuição dos resultados.  \n",
    "\n",
    "### Vantagens da Validação Cruzada\n",
    "- Permite avaliar a robustez do classificador, verificando se ele mantém desempenho estável em diferentes cenários.  \n",
    "- Reduz o risco de avaliar o modelo apenas com uma divisão específica, que poderia não ser representativa.  \n",
    "- Mostra como o desempenho varia conforme a composição do treino e do teste.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validação Cruzada Estratificada (10 folds)\n",
      "\n",
      "Fold 1 : Acurácia = 60.56 %\n",
      "Fold 2 : Acurácia = 56.11 %\n",
      "Fold 3 : Acurácia = 66.39 %\n",
      "Fold 4 : Acurácia = 59.17 %\n",
      "Fold 5 : Acurácia = 65.28 %\n",
      "Fold 6 : Acurácia = 63.33 %\n",
      "Fold 7 : Acurácia = 66.94 %\n",
      "Fold 8 : Acurácia = 66.67 %\n",
      "Fold 9 : Acurácia = 59.17 %\n",
      "Fold 10 : Acurácia = 62.78 %\n",
      "\n",
      "Acurácia Média = 62.64 %\n"
     ]
    }
   ],
   "source": [
    "#junta os dados de treino e teste em um único dataframe \n",
    "dados_completos = pd.concat([train, test])\n",
    "\n",
    "#define X como os textos e y como os rótulos (targets)\n",
    "X = dados_completos[\"Text\"].values\n",
    "y = dados_completos[\"target\"].values\n",
    "\n",
    "#cria o objeto para validação cruzada estratificada\n",
    "# n_splits=10 -> divide os dados em 10 partes (folds)\n",
    "# shuffle=True -> embaralha os dados antes de dividir\n",
    "# random_state=42 -> garante reprodutibilidade (sempre a mesma divisão)\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "#lista para armazenar a acurácia de cada fold\n",
    "lista_acuracia = []\n",
    "\n",
    "print(\"Validação Cruzada Estratificada (10 folds)\\n\")\n",
    "\n",
    "#loop para rodar a validação em 10 folds\n",
    "for i, (idx_treino, idx_teste) in enumerate(kf.split(X, y)):\n",
    "    #cria os conjuntos de treino e teste deste fold\n",
    "    df_treino = dados_completos.iloc[idx_treino]\n",
    "    df_teste = dados_completos.iloc[idx_teste]\n",
    "    \n",
    "    #conta as palavras no conjunto de treino (gera estatísticas do Naive Bayes)\n",
    "    cont_neg, cont_neu, cont_pos, cont_total, P_neg, P_neu, P_pos = contar_palavras(df_treino)\n",
    "    \n",
    "    respostas_previstas = []  # previsões feitas neste fold\n",
    "    \n",
    "    #classifica cada texto do conjunto de teste\n",
    "    for texto in df_teste[\"Text\"]:\n",
    "        classe, _, _ = classificar_texto(texto, cont_neg, cont_neu, cont_pos, cont_total, P_neg, P_neu, P_pos)\n",
    "        respostas_previstas.append(classe)\n",
    "    \n",
    "    #rótulos verdadeiros deste fold\n",
    "    respostas_reais = df_teste[\"target\"].values\n",
    "    \n",
    "    #conta os acertos\n",
    "    acertos = 0\n",
    "    for j in range(len(respostas_reais)):\n",
    "        if respostas_reais[j] == respostas_previstas[j]:\n",
    "            acertos = acertos + 1\n",
    "    \n",
    "    #calcula acurácia do fold\n",
    "    acuracia = acertos / len(respostas_reais)\n",
    "    lista_acuracia.append(acuracia * 100)  # armazena em porcentagem\n",
    "    \n",
    "    #imprime resultado do fold\n",
    "    print(\"Fold\", i+1, \": Acurácia =\", round(acuracia*100, 2), \"%\")\n",
    "\n",
    "#calcula a média final de acurácia\n",
    "media = np.mean(lista_acuracia)\n",
    "print(\"\\nAcurácia Média =\", round(media, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plota um histograma com as acurácias obtidas em cada fold da validação cruzada\n",
    "plt.hist(lista_acuracia, bins=5, edgecolor=\"black\")\n",
    "plt.title(\"Distribuição das Acurácias (10 folds)\")\n",
    "plt.xlabel(\"Acurácia (%)\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Discussão crítica\n",
    "\n",
    "- **Acurácia média**: **62,64 %**  \n",
    "- **Acurácia mínima**: **56,11 %**  \n",
    "- **Acurácia máxima**: **66,94 %**  \n",
    "\n",
    "O histograma mostrou que a maior parte dos folds ficou concentrada na faixa de 60%–63%, indicando consistência razoável, mas ainda com algumas flutuações.\n",
    "\n",
    "\n",
    "#### Interpretação do histograma\n",
    "- O modelo se mostrou razoavelmente estável, já que a maioria dos resultados ficou próxima da média.  \n",
    "- Entretanto, há alguma sensibilidade à divisão dos dados: em alguns folds, a acurácia caiu para perto de 56%, revelando que certas composições do conjunto de teste tornam a classificação mais difícil.  \n",
    "- Essa variação está relacionada, principalmente, à classe Neutro, que compartilha vocabulário com as demais e pode desbalancear o desempenho dependendo da divisão.\n",
    "\n",
    "#### Desvantagens de uma divisão única\n",
    "- **Alto risco de viés**: se a divisão não for representativa (por exemplo, com muitos textos neutros concentrados no teste), o resultado pode ser artificialmente pior ou melhor.  \n",
    "- **Menor aproveitamento da base**: parte dos dados nunca é usada para treinar, reduzindo a quantidade de informação para o modelo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Conclusões\n",
    "\n",
    "A validação cruzada mostrou que o Naive Bayes tem desempenho médio de ~63%, com variação moderada entre os folds.  \n",
    "Isso indica que o modelo é razoavelmente consistente, mas ainda depende da composição dos conjuntos de treino e teste, sobretudo pela dificuldade em classificar frases neutras.  \n",
    "\n",
    "O histograma reforça a importância de não confiar em apenas uma divisão única de treino/teste, mas sim de avaliar o classificador em diferentes cenários para obter uma visão mais realista de sua performance.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Leia atentamente a rubrica colocada no enunciado do Projeto 1 (última página). <br>\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nas mensagens, mas tendem a melhorar na classificação das mensagens. Ex: stemming, lemmatization, stopwords.\n",
    "* CONSIDEROU arquivo com três categorias na classificação das variáveis (OBRIGATÓRIO PARA QUARTETOS, sem contar como item avançado)\n",
    "* CONSTRUIU o cálculo das probabilidades corretamente utilizando bigramas E apresentou referência sobre o método utilizado.\n",
    "* EXPLICOU porquê não pode usar novas mensagens classificadas pelo próprio classificador como amostra de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto (pelo menos dois cenários diferentes, exceto aqueles já apresentados em sala pelos professores: por exemplo, filtro de spam)\n",
    "* REFLETE criticamente sobre os resultados obtidos, identificando limitações do modelo e sugerindo possíveis melhorias ou diferentes abordagens com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa).\n",
    "* DOCUMENTOU bem o código, com explicações claras para cada etapa do processo, incluindo o raciocínio por trás das decisões de modelagem e das transformações de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Speech and Language Processing – Jurafsky & Martin (Draft 3rd Edition)](https://web.stanford.edu/~jurafsky/slp3/)  \n",
    "→ Referência clássica em PLN, cobrindo Naive Bayes, bigramas, stemming, lematização e embeddings.\n",
    "\n",
    "[Introduction to Information Retrieval – Manning, Raghavan & Schütze (2008)](https://nlp.stanford.edu/IR-book/) \n",
    "→ Livro referência em classificação de texto, modelos probabilísticos e recuperação de informação.\n",
    "\n",
    "[Natural Language Processing with Python – NLTK Book](https://www.nltk.org/book/)  \n",
    "→ Fonte prática para implementação de lematização, stemming e stopwords em Python.\n",
    "\n",
    "[Word2Vec – Mikolov et al. (2013)](https://arxiv.org/pdf/1301.3781.pdf) \n",
    "→ Artigo que introduz representações vetoriais eficientes (embeddings).\n",
    "\n",
    "[BERT – Devlin et al. (2018)](https://arxiv.org/pdf/1810.04805.pdf) \n",
    "→ Modelo baseado em Transformers, resolve problemas de contexto, ironia e sarcasmo melhor do que Naive Bayes.\n",
    "\n",
    "[Naive Bayes and Text Classification – Zhang (2014)](https://arxiv.org/pdf/1410.5329.pdf) \n",
    "→ Explicação técnica aprofundada sobre Naive Bayes aplicado a classificação de texto.\n",
    "\n",
    "[Natural Language Processing (Part 17) – Laplacian Smoothing](https://medium.com/@Coursesteach/natural-language-processing-part-17-laplacian-smoothing-7d4be71d0ded) \n",
    "→ Explicação didática sobre a suavização de Laplace aplicada ao Naive Bayes.\n",
    "\n",
    "[Practical Explanation of Naive Bayes Classifier – Monkeylearn (2019)](https://web.archive.org/web/20240222071715/https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/)   \n",
    "→ Tutorial prático sobre o funcionamento do Naive Bayes e suas aplicações.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
